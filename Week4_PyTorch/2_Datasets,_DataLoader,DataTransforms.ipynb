{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Creating Custom Dataset and DataLoader**"],"metadata":{"id":"d2D_rfAE8vMH"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"GDiSG5WY1Snw","outputId":"1f21d683-547c-4d1c-d091-642c6c73417f","executionInfo":{"status":"error","timestamp":1745773178417,"user_tz":-330,"elapsed":25995,"user":{"displayName":"SHREYA AGRAWAL","userId":"04870259387058083557"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"/content/Wine dataset.csv not found.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8ef89bc25e1b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# create dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# get first sample and unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-8ef89bc25e1b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Initialize data, download, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# read with numpy or pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Wine dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1382\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: /content/Wine dataset.csv not found."]}],"source":["import torch\n","import torchvision\n","#Torchvision is a PyTorch package that provides datasets, model architectures, and\n","#image transformations for computer vision tasks.\n","#Torchvision includes popular datasets like MNIST, CIFAR10, ImageNet, and COCO.\n","\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import math\n","\n","# gradient computation etc. not efficient for whole data set\n","# -> divide dataset into small batches\n","\n","'''\n","# training loop\n","for epoch in range(num_epochs):\n","    # loop over all batches\n","    for i in range(total_batches):\n","        batch_x, batch_y = ...\n","'''\n","\n","# epoch = one forward and backward pass of ALL training samples\n","# batch_size = number of training samples used in one forward/backward pass\n","# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n","# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n","\n","# --> DataLoader can do the batch computation for us\n","\n","# Implement a custom Dataset:\n","# inherit Dataset\n","# implement __init__ , __getitem__ , and __len__\n","\n","class WineDataset(Dataset):\n","\n","    def __init__(self):\n","        # Initialize data, download, etc.\n","        # read with numpy or pandas\n","        xy = np.loadtxt('/content/Wine dataset.csv', delimiter=',', dtype=np.float32, skiprows=1)\n","        self.n_samples = xy.shape[0]\n","\n","        # here the first column is the class label, the rest are the features\n","        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n","        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n","#Link to get wine.csv file: 'https://drive.google.com/file/d/1IOwX2ztUO18eazs8wtlfSS-U5FA-knNu/view?usp=drive_link'\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples\n","\n","\n","# create dataset\n","dataset = WineDataset()\n","\n","# get first sample and unpack\n","first_data = dataset[0]\n","features, labels = first_data\n","print(features, labels)\n","\n","# Load whole dataset with DataLoader\n","# shuffle: shuffle data, good for training\n","# num_workers: faster loading with multiple subprocesses\n","# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=4,\n","                          shuffle=True,\n","                          num_workers=2)\n","\n","# convert to an iterator and look at one random sample\n","dataiter = iter(train_loader)\n","data = next(dataiter)\n","features, labels = data\n","print(features, labels)\n","\n","# Dummy Training loop\n","num_epochs = 2\n","total_samples = len(dataset)\n","n_iterations = math.ceil(total_samples/4)\n","print(total_samples, n_iterations)\n","for epoch in range(num_epochs):\n","    for i, (inputs, labels) in enumerate(train_loader):\n","\n","        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n","        # Run your training process\n","        if (i+1) % 5 == 0:\n","            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n"]},{"cell_type":"markdown","source":["**TorchVision Inbuilt Datasets**"],"metadata":{"id":"-zRvTSoeLqpe"}},{"cell_type":"code","source":["# some famous datasets are available in torchvision.datasets\n","# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n","\n","train_dataset = torchvision.datasets.MNIST(root='./data',\n","                                           train=True,\n","                                           transform=torchvision.transforms.ToTensor(),\n","                                           download=True)\n","\n","train_loader = DataLoader(dataset=train_dataset,\n","                                           batch_size=3,\n","                                           shuffle=True)\n","\n","# look at one random sample\n","dataiter = iter(train_loader)\n","data = next(dataiter)\n","inputs, targets = data\n","print(inputs.shape, targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jl1blrgB1Ff","outputId":"f298fed1-8293-4fad-bdf2-d7851212137d","executionInfo":{"status":"ok","timestamp":1744732011012,"user_tz":-330,"elapsed":1983,"user":{"displayName":"Sanidhya Sharma","userId":"11244205970451029434"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 49.3MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 1.54MB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 13.4MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 8.09MB/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1, 28, 28]) torch.Size([3])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["**Data Transformations**"],"metadata":{"id":"L79VfViKCeJq"}},{"cell_type":"markdown","source":["'''\n","Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n","during creation of the DataSet\n","\n","complete list of built-in transforms:\n","https://pytorch.org/docs/stable/torchvision/transforms.html\n","\n","On Images\n","---------\n","CenterCrop, Grayscale, Pad, RandomAffine\n","RandomCrop, RandomHorizontalFlip, RandomRotation\n","Resize, Scale\n","\n","On Tensors\n","----------\n","LinearTransformation, Normalize, RandomErasing\n","\n","Conversion\n","----------\n","ToPILImage: from tensor or ndrarray\n","ToTensor : from numpy.ndarray or PILImage\n","\n","Generic\n","-------\n","Use Lambda\n","\n","Custom\n","------\n","Write own class\n","\n","Compose multiple Transforms\n","---------------------------\n","composed = transforms.Compose([Rescale(256),\n","                               RandomCrop(224)])\n","'''"],"metadata":{"id":"PvqzKhh4Cj_B"}},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"5GHImCEG-oA0"}},{"cell_type":"code","source":[],"metadata":{"id":"84HsEFy6LmXt"},"execution_count":null,"outputs":[]}]}